{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Yp1XJNNKo4oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MnaDwcIoXHU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "from skimage import io\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pafy"
      ],
      "metadata": {
        "id": "dovMOJPy2MEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-dl"
      ],
      "metadata": {
        "id": "WWYcECZQ2VwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio==2.4.1"
      ],
      "metadata": {
        "id": "2hlXYRkq2fdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/New_Code/New model')"
      ],
      "metadata": {
        "id": "OgU_bn4zu12S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJWAyr_soXHf"
      },
      "outputs": [],
      "source": [
        "import vidsumm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG8zlte7oXHi"
      },
      "outputs": [],
      "source": [
        "Path=\"/content/drive/MyDrive/New_Code/New model/trained_model19_1.pt\"\n",
        "retr_model1 = vidsumm.load_model5(Path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plihomSIoXHj"
      },
      "outputs": [],
      "source": [
        "Path=\"/content/drive/MyDrive/New_Code/New model/trained_model19_1_glove.pt\"\n",
        "retr_model2 = vidsumm.load_model5_glove(Path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQuL7mYtoXHl"
      },
      "outputs": [],
      "source": [
        "Path=\"/content/drive/MyDrive/New_Code/New model/trained_model9_1_glove.pt\"\n",
        "retr_model3 = vidsumm.load_model4_glove(Path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbzD4OeXoXHn"
      },
      "outputs": [],
      "source": [
        "# Define the transform \n",
        "train_transform = transforms.Compose([\n",
        "        transforms.Resize((224,224)),             # takes PIL image as input and outputs PIL image\n",
        "        transforms.ToTensor(),              # takes PIL image as input and outputs torch.tensor\n",
        "        transforms.Normalize(mean=[0.4280, 0.4106, 0.3589],  # takes tensor and outputs tensor\n",
        "                             std=[0.2737, 0.2631, 0.2601]),  # see next step for mean and std\n",
        "    ])\n",
        "\n",
        "valid_transform = transforms.Compose([ \n",
        "        transforms.Resize((224,224)),             \n",
        "#         transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.4280, 0.4106, 0.3589],\n",
        "                             std=[0.2737, 0.2631, 0.2601]), \n",
        "    ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize((224,224)),             \n",
        "#         transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.4280, 0.4106, 0.3589],\n",
        "                             std=[0.2737, 0.2631, 0.2601]), \n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fxb86JqeoXHt"
      },
      "outputs": [],
      "source": [
        "w2vmodel = vidsumm.get_word2vec_function()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove = vidsumm.get_glove_function()"
      ],
      "metadata": {
        "id": "8CbodsKHtidO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox3X7v74oXHw"
      },
      "outputs": [],
      "source": [
        "videoURL=\"https://www.youtube.com/watch?v=1L1RdktmbF0\"\n",
        "query=\"lion running\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMpPyZNMoXHz"
      },
      "outputs": [],
      "source": [
        "from vidsumm.utils_func import preprocess_video\n",
        "imagenames = preprocess_video(query,videoURL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax-7Tt5foXH0"
      },
      "outputs": [],
      "source": [
        "def prep_input(imagenames, query):\n",
        "    \n",
        "    ip_image = []\n",
        "    for i in range(len(imagenames)):\n",
        "        image = io.imread(imagenames[i])\n",
        "        image = test_transform(Image.fromarray(image))\n",
        "        ip_image.append(image)\n",
        "    \n",
        "    query = \"lion running\"\n",
        "    query = query.lower()\n",
        "    query = ' '.join(word for word in query.split(' ') if word in w2vmodel.vocab)\n",
        "    words = query.split()\n",
        "    SEQ_LENGTH = 8\n",
        "    num_features = 300\n",
        "    BATCH_SIZE = 1\n",
        "    qdata = np.zeros((SEQ_LENGTH, num_features), dtype=np.float32)\n",
        "    mask = np.ones((BATCH_SIZE, SEQ_LENGTH), dtype=np.bool)\n",
        "    for j in range(SEQ_LENGTH):\n",
        "        if j < len(words):\n",
        "            qdata[j, :] = np.array(w2vmodel[str(words[j])])\n",
        "\n",
        "    #qdata = qdata.mean(axis=0)\n",
        "\n",
        "    qdata = torch.from_numpy(qdata)\n",
        "    \n",
        "    return ip_image, qdata\n",
        "\n",
        "def prep_input_glove(imagenames, query):\n",
        "    \n",
        "    ip_image = []\n",
        "    for i in range(len(imagenames)):\n",
        "        image = io.imread(imagenames[i])\n",
        "        image = test_transform(Image.fromarray(image))\n",
        "        ip_image.append(image)\n",
        "    \n",
        "    query = \"lion running\"\n",
        "    query = query.lower()\n",
        "    query = ' '.join(word for word in query.split(' ') if word in glove.vocab)\n",
        "    words = query.split()\n",
        "    SEQ_LENGTH = 8\n",
        "    num_features = 200\n",
        "    BATCH_SIZE = 1\n",
        "    qdata = np.zeros((SEQ_LENGTH, num_features), dtype=np.float32)\n",
        "    mask = np.ones((BATCH_SIZE, SEQ_LENGTH), dtype=np.bool)\n",
        "    for j in range(SEQ_LENGTH):\n",
        "        if j < len(words):\n",
        "            qdata[j, :] = np.array(glove[str(words[j])])\n",
        "\n",
        "    #qdata = qdata.mean(axis=0)\n",
        "\n",
        "    qdata = torch.from_numpy(qdata)\n",
        "    \n",
        "    return ip_image, qdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iycsEVUroXH1"
      },
      "outputs": [],
      "source": [
        "def predict1(ip_image, qdata):\n",
        "    \n",
        "    qdata = qdata.cuda()\n",
        "    qdata = torch.unsqueeze(qdata,0)\n",
        "    selected = {}\n",
        "    for i in range(len(ip_image)):\n",
        "        image = ip_image[i]\n",
        "        image = image.cuda()\n",
        "        image = torch.unsqueeze(image,0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = retr_model1(image, qdata)\n",
        "        max_values_relevance, arg_maxs_relevance = torch.max(output, dim = 1)\n",
        "        #print(arg_maxs_relevance)\n",
        "        if(arg_maxs_relevance.item() >= 2):\n",
        "            selected[i] = max_values_relevance.item()\n",
        "        \n",
        "    return selected\n",
        "\n",
        "def predict2(ip_image, qdata):\n",
        "    \n",
        "    qdata = qdata.cuda()\n",
        "    qdata = torch.unsqueeze(qdata,0)\n",
        "    selected = {}\n",
        "    for i in range(len(ip_image)):\n",
        "        image = ip_image[i]\n",
        "        image = image.cuda()\n",
        "        image = torch.unsqueeze(image,0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = retr_model2(image, qdata)\n",
        "        max_values_relevance, arg_maxs_relevance = torch.max(output, dim = 1)\n",
        "        #print(arg_maxs_relevance)\n",
        "        if(arg_maxs_relevance.item() >= 2):\n",
        "            selected[i] = max_values_relevance.item()\n",
        "        \n",
        "    return selected\n",
        "\n",
        "def predict3(ip_image, qdata):\n",
        "    \n",
        "    qdata = qdata.cuda()\n",
        "    qdata = torch.unsqueeze(qdata,0)\n",
        "    selected = {}\n",
        "    for i in range(len(ip_image)):\n",
        "        image = ip_image[i]\n",
        "        image = image.cuda()\n",
        "        image = torch.unsqueeze(image,0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = retr_model3(image, qdata)\n",
        "        max_values_relevance, arg_maxs_relevance = torch.max(output, dim = 1)\n",
        "        #print(arg_maxs_relevance)\n",
        "        if(arg_maxs_relevance.item() >= 2):\n",
        "            selected[i] = max_values_relevance.item()\n",
        "        \n",
        "    return selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeAYDUmQoXH3"
      },
      "outputs": [],
      "source": [
        "ip_image, qdata = prep_input(imagenames, query)\n",
        "ip_image_glove, qdata1_glove = prep_input_glove(imagenames, query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcnVEDVZoXH4"
      },
      "outputs": [],
      "source": [
        "selected1 = predict1(ip_image, qdata)\n",
        "selected2 = predict2(ip_image_glove, qdata1_glove)\n",
        "selected3 = predict3(ip_image_glove, qdata1_glove)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Model1"
      ],
      "metadata": {
        "id": "X0YNFp8ScZUG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVsnG0troXH5"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "selected = sorted(selected1.items(), key = itemgetter(1), reverse = True)[:10]\n",
        "selected = sorted(selected, key = itemgetter(0))\n",
        "selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWkJ2dQeoXH6"
      },
      "outputs": [],
      "source": [
        "for i in range(len(selected)):\n",
        "    print(selected[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Te5WBpM_oXH6"
      },
      "outputs": [],
      "source": [
        "import matplotlib .pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "plt.figure(figsize=(60, 10))\n",
        "for i in range(len(selected)):\n",
        "    plt.subplot(len(selected)/5,5, i+1);plt.imshow(mpimg.imread(\"/content/drive/MyDrive/New_Code/New model/videos/\" + query + \"/frames/\"+str(selected[i][0])+\".png\"));plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Model 2"
      ],
      "metadata": {
        "id": "p7SklkiQcrqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected = sorted(selected2.items(), key = itemgetter(1), reverse = True)[:10]\n",
        "selected = sorted(selected, key = itemgetter(0))\n",
        "selected"
      ],
      "metadata": {
        "id": "vhqGZuNOY-iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(selected)):\n",
        "    print(selected[i][0])"
      ],
      "metadata": {
        "id": "Q_CHPfL1ZBON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib .pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "plt.figure(figsize=(60, 10))\n",
        "for i in range(len(selected)):\n",
        "    plt.subplot(len(selected)/5,5, i+1);plt.imshow(mpimg.imread(\"/content/drive/MyDrive/New_Code/New model/videos/\" + query + \"/frames/\"+str(selected[i][0])+\".png\"));plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7C6Ek0YQZEOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Model 3"
      ],
      "metadata": {
        "id": "Vmk8vRNXcvsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected = sorted(selected3.items(), key = itemgetter(1), reverse = True)[:10]\n",
        "selected = sorted(selected, key = itemgetter(0))\n",
        "selected"
      ],
      "metadata": {
        "id": "ZguZ5SSQZGDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(selected)):\n",
        "    print(selected[i][0])"
      ],
      "metadata": {
        "id": "d970PS_BZJ4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib .pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "plt.figure(figsize=(60, 10))\n",
        "for i in range(len(selected)):\n",
        "    plt.subplot(len(selected)/5,5, i+1);plt.imshow(mpimg.imread(\"/content/drive/MyDrive/New_Code/New model/videos/\" + query + \"/frames/\"+str(selected[i][0])+\".png\"));plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bb-TnBPlZMFV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}